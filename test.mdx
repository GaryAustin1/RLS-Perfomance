<span style="color:red">DON'T USE STILL GIBBERISH</span>


## RLS Performance and Best Practices

Although most of the time spent on thinking about RLS is to get it to handle security needs, the impact of it on performance
of your queries can be massive.
This is especially true on queries that look at every row in a table like for many select operations and updates with where clauses.

Please see the [last section](#tools-to-measure-performance) for ways to measure the performance of you queries as you test RLS improvements.

### Is RLS causing my peformance issue (on a single table query)?

For very slow queries, or if using the tools at end of article, run a query with RLS enabled on the table and then with it disabled.  If the results are similar then your query itself is likely the performance issue.

### How to improve RLS peformance.

The following tips are very broad and each may or may not help the specific case involved.  Some changes, like adding indexes, should be backed out if they do not make a difference in RLS performance and you are not using them for filtering performance.

#### The first thing to try is put an index on columns used in the RLS that are not primary keys or unique already.  
For RLS like:  
`auth.uid() = user_id`  
Add an index like:  
`create index userid on test_table using btree (user_id) tablespace pg_default;`  
Improvement seen over 100x on large tables.

#### Another method to improve performance is to wrap your RLS queries and functions in a select statements. 
WARNING:  You can only do this if the results of the query do not change based on the row data.
For RLS like this:  
`is_admin() or auth.uid() = user_id`  
Use this instead:  
`(select is_admin()) OR (select auth.uid() = user_id)`  
** see LINK for SQL for functions and code used...   

#### Do not rely on RLS for filtering but only for security.  
Instead of doing this:    
`.from('table').select()`     
With an RLS policy of:  
`auth.uid() = user_id`    
Add a filter in addition to the RLS:  
`.from('table').select().eq('user_id',userId)`

#### Use security definer functions to do queries on other tables to bypass their RLS when possible.    
Instead of having this RLS where the roles_table has an RLS select policy of `auth.uid() = user_id`:  
`exists (select 1 from team_table where auth.uid() = user_id and role = "good_role")`  
Create a security definer function has_role() (see link) and do:  
`has_role()` with code of `exists (select 1 from roles_table where uath.uid() = user_id and role = "good_role")`  

#### Use role in TO option or roles dropdown in the dashboard.  
Never just use RLS involving auth.uid() or auth.jwt() as your way to rule out 'anon' role.    
Always add 'authenticated' to the approved roles instead of nothing or public.  
Although this does not improve the query performance for the signed in user it does
eliminate 'anon' users without taxing the database to process the rest of the RLS.

### Sample results

The code used for the below tests can be found here: LINK:

Show RLS and before after for above examples.

| Test | RLS Before  |  RLS After   | SQL Before |  SQL After | JS Before | JS After |  
|-----|------------------------|---------------------------|---------|---------|---|---- |  
| 1 | auth.uid() = user_id |user_id indexed | 171| <.1|  731 | <.1 |  


### Tools to measure performance

Postgres has tools to analyze the peformance of queries.  https://www.postgresql.org/docs/current/sql-explain.html
The use of explain in detail for query analysis is beyond the scope of this discussion.
Here we will use it mainly to get a performance metric to compare times.

PostgREST allows use of explain to get performance information on your queries with Supabase clients.

Before using this feature you need to run the following command in the Dashboad SQL editor (should not be used in production):
```sql
set pgrst.db_plan_enabled to true;
```
Then you can use the .explain() modifier to get performance metrics.
```js
const { data, error } = await supabase
  .from('projects')
  .select('*')
  .eq('id', 1)
  .explain({ analyze: true })

console.log(data)
```
This will return a result like:
```
Aggregate  (cost=8.18..8.20 rows=1 width=112) (actual time=0.017..0.018 rows=1 loops=1)
  ->  Index Scan using projects_pkey on projects  (cost=0.15..8.17 rows=1 width=40) (actual time=0.012..0.012 rows=0 loops=1)
        Index Cond: (id = 1)
        Filter: false
        Rows Removed by Filter: 1
Planning Time: 0.092 ms
Execution Time: 0.046 ms
```
In this case the execution time is the critical number we need to compare.

This performance analysis can also be done in the SQL editor by setting a user role and fake jwt claims information for use in the RLS.

```SQL
set local role authenticated;
set request.jwt.claims to '{"role":"authenticated", "sub":"5950b438-b07c-4012-8190-6ce79e4bd8e5"}';
explain analyze SELECT * FROM projects where id = 1;
```





